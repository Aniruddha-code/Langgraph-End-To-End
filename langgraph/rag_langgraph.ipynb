{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c676b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "#os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7285d217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm_groq = ChatGroq(model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d423f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm doing well, thanks for asking. I'm a large language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help with any questions or tasks you may have. How about you? How's your day going so far?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 40, 'total_tokens': 99, 'completion_time': 0.100025287, 'prompt_time': 0.002435164, 'queue_time': 0.052407726, 'total_time': 0.102460451}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c7198415-4f08-4741-8c5d-95172236d772-0', usage_metadata={'input_tokens': 40, 'output_tokens': 59, 'total_tokens': 99})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_groq.invoke(\"Hi, How are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abfbcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0a125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('../data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3420f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c6463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aniruddha\\AppData\\Local\\Temp\\ipykernel_9380\\3753552593.py:8: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceBgeEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "###  BGE Embddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa4d4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f603af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Retriever using Vector DB\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a253d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '..\\\\data\\\\lamma3.txt'}, page_content='Model weights for the first version of Llama were released to the research community under a'), Document(metadata={'source': '..\\\\data\\\\lamma3.txt'}, page_content='70B.[4] Originally, Llama was only available as a foundation model.[8] Starting with Llama 2, Meta'), Document(metadata={'source': '..\\\\data\\\\lamma3.txt'}, page_content='under a non-commercial license.[5][3] Subsequent versions of Llama were made accessible outside'), Document(metadata={'source': '..\\\\data\\\\lamma3.txt'}, page_content='by Meta AI starting in February 2023.[2][3] The latest version is Llama 3 released in April')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aniruddha\\AppData\\Local\\Temp\\ipykernel_9380\\2266497744.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about llama3?\"\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6d1645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5054f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DirectoryLoader(\"../data\",glob=\"./*.txt\",loader_cls=TextLoader)\n",
    "docs=loader.load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f7b0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad0854ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '..\\\\data\\\\lamma3.txt'}\n",
      "70B.[4] Originally, Llama was only available as a foundation model.[8] Starting with Llama 2, Meta\n",
      "page_content='70B.[4] Originally, Llama was only available as a foundation model.[8] Starting with Llama 2, Meta' metadata={'source': '..\\\\data\\\\lamma3.txt'}\n",
      "page_content='by Meta AI starting in February 2023.[2][3] The latest version is Llama 3 released in April' metadata={'source': '..\\\\data\\\\lamma3.txt'}\n",
      "page_content='by Meta AI starting in February 2023.[2][3] The latest version is Llama 3 released in April' metadata={'source': '..\\\\data\\\\lamma3.txt'}\n"
     ]
    }
   ],
   "source": [
    "query = \"what is meta llama3?\"\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "print(docs[0].metadata)\n",
    "print(docs[0].page_content)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28444845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(AgentState):\n",
    "    \n",
    "    message=AgentState[\"messages\"]\n",
    "    \n",
    "    question=message[-1]\n",
    "    print(\"Question received:\", question)\n",
    "    \n",
    "    complete_prompt=\"Your task is to provide only the brief answer based on the user query. \\\n",
    "        Don't include too much reasoning. Following is the user query: \" + question\n",
    "    \n",
    "    response = llm_groq.invoke(complete_prompt)\n",
    "    \n",
    "    AgentState['messages'].append(response.content) # appending LLM call response to the AgentState\n",
    "    \n",
    "    #print(AgentState)\n",
    "    \n",
    "    return AgentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b22c05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentState={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db42b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentState[\"messages\"]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6451187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8413489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentState[\"messages\"].append(\"hi, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "915f37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(AgentState):\n",
    "    messages = AgentState['messages']\n",
    "    question = messages[0] ## Fetching the user question\n",
    "\n",
    "    template = \"\"\"Answer the question based only on the following context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    retrieval_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm_groq\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "    result = retrieval_chain.invoke(question)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf313f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The 'messages' field should be a sequence of strings, and we annotate it with 'operator.add'\n",
    "    # This implies we might want to \"add\" new messages to the sequence later\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13b7e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START,END\n",
    "workflow4 = StateGraph(AgentState)\n",
    "workflow4.add_node(\"LLM\", function_1)\n",
    "workflow4.add_node(\"RAGtool\", function_2)\n",
    "workflow4.add_edge('LLM', 'RAGtool')\n",
    "workflow4.set_entry_point(\"LLM\")\n",
    "workflow4.set_finish_point(\"RAGtool\")\n",
    "app4 = workflow4.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1103b9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app4.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "547523bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [\"Tell me about llama3 model\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94de1c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question received: Tell me about llama3 model\n",
      "Output from node 'LLM':\n",
      "---\n",
      "{'messages': ['Tell me about llama3 model', 'Llama3 is a large language model developed by Meta, designed for natural language processing and generation tasks.']}\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "Expected dict, got Based on the provided context, here's what is known about the Llama model:\n\n1. Llama models are trained at different parameter sizes, typically ranging (no specific range is mentioned in the context).\n2. Model weights for the first version of Llama were released to the research community under a certain license or agreement (the specifics of which are not mentioned in the context).\n3. The Llama model has some restrictions related to \"commercial use\" (as mentioned in the first document), but the details are not provided.\n\nThere is no specific information available in the context about a \"llama3 model\". The context only mentions \"Llama\" in general.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp4\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# stream() yields dictionaries with output keyed by node name\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOutput from node \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2674\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2672\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2673\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2679\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2684\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:659\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    657\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    658\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\langgraph\\pregel\\_write.py:87\u001b[39m, in \u001b[36mChannelWrite._write\u001b[39m\u001b[34m(self, input, config)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     79\u001b[39m     writes = [\n\u001b[32m     80\u001b[39m         ChannelWriteEntry(write.channel, \u001b[38;5;28minput\u001b[39m, write.skip_none, write.mapper)\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write.value \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.writes\n\u001b[32m     86\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\langgraph\\pregel\\_write.py:129\u001b[39m, in \u001b[36mChannelWrite.do_write\u001b[39m\u001b[34m(config, writes, allow_passthrough)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# if we want to persist writes found before hitting a ParentCommand\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# can move this to a finally block\u001b[39;00m\n\u001b[32m    128\u001b[39m write: TYPE_SEND = config[CONF][CONFIG_KEY_SEND]\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m write(\u001b[43m_assemble_writes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\langgraph\\pregel\\_write.py:184\u001b[39m, in \u001b[36m_assemble_writes\u001b[39m\u001b[34m(writes)\u001b[39m\n\u001b[32m    182\u001b[39m     tuples.append((TASKS, w))\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteTupleEntry):\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ww := \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    185\u001b[39m         tuples.extend(ww)\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteEntry):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PythonCode\\Langgraph-End-To-End\\langgraphvenv\\Lib\\site-packages\\langgraph\\graph\\state.py:992\u001b[39m, in \u001b[36mCompiledStateGraph.attach_node.<locals>._get_updates\u001b[39m\u001b[34m(input)\u001b[39m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    988\u001b[39m     msg = create_error_message(\n\u001b[32m    989\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected dict, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    990\u001b[39m         error_code=ErrorCode.INVALID_GRAPH_NODE_RETURN_VALUE,\n\u001b[32m    991\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m992\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: Expected dict, got Based on the provided context, here's what is known about the Llama model:\n\n1. Llama models are trained at different parameter sizes, typically ranging (no specific range is mentioned in the context).\n2. Model weights for the first version of Llama were released to the research community under a certain license or agreement (the specifics of which are not mentioned in the context).\n3. The Llama model has some restrictions related to \"commercial use\" (as mentioned in the first document), but the details are not provided.\n\nThere is no specific information available in the context about a \"llama3 model\". The context only mentions \"Llama\" in general.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
      "During task with name 'RAGtool' and id 'b8ad683f-dedf-93de-bdce-c79100274c93'"
     ]
    }
   ],
   "source": [
    "for output in app4.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "130946af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = DirectoryLoader(\n",
    "    \"../data2\",\n",
    "    glob=\"./*.txt\",\n",
    "    loader_cls=lambda path: TextLoader(path, encoding=\"utf-8\")\n",
    ")\n",
    "docs2=loader2.load()\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "new_docs2 = text_splitter.split_documents(documents=docs2)\n",
    "doc_strings2 = [doc.page_content for doc in new_docs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d95d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = Chroma.from_documents(new_docs2, embeddings)\n",
    "retriever2 = db2.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "889b9634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '..\\\\data2\\\\indian.txt'}\n",
      "India’s industrial growth has outpaced expectations, raising hopes that the economy will avoid a\n",
      "page_content='India’s industrial growth has outpaced expectations, raising hopes that the economy will avoid a' metadata={'source': '..\\\\data2\\\\indian.txt'}\n",
      "page_content='Industrial Revival and Economic Optimism for India' metadata={'source': '..\\\\data2\\\\indian.txt'}\n",
      "page_content='for India’s economy. “We are encouraged by the steady rise in domestic consumption and industrial' metadata={'source': '..\\\\data2\\\\indian.txt'}\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about India's Industrial Growth?\"\n",
    "docs = retriever2.get_relevant_documents(query)\n",
    "print(docs[0].metadata)\n",
    "print(docs[0].page_content)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ad42c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dedf766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    # The 'messages' field should be a sequence of strings, and we annotate it with 'operator.add'\n",
    "    # This implies we might want to \"add\" new messages to the sequence later\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc1ec00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel , Field\n",
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic: str = Field(description='Selected Topic')\n",
    "    Reasoning: str = Field(description='Reasoning behind topic selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69cc1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "parser = PydanticOutputParser(pydantic_object=TopicSelectionParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80f99ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"Topic\": {\"description\": \"Selected Topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71f66f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state):\n",
    "    message=state[\"messages\"]\n",
    "    question=message[-1]\n",
    "    print(question)\n",
    "    \n",
    "    template=\"\"\"\n",
    "    Your task is to classify the given user query into one of the following categories: [India, Not Related]. \n",
    "    Only respond with the category name and nothing else.\n",
    "\n",
    "    User query: {question}\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(template=template,\n",
    "                                    input_variables=[question],\n",
    "                                    partial_variables={\n",
    "                                        \"format_instructions\" : parser.get_format_instructions()                                    }\n",
    "                                    )\n",
    "    chain =  prompt | llm_groq | parser\n",
    "    \n",
    "    response = chain.invoke({\"question\":question,\"format_instructions\" : parser.get_format_instructions() })\n",
    "\n",
    "    print(response)\n",
    "\n",
    "    return {\"messages\": [response.Topic]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27e92529",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "    Your task is to classify the given user query into one of the following categories: [India, Not Related]. \n",
    "    Only respond with the category name and nothing else.\n",
    "\n",
    "    User query: \"Tell me about India's Industrial Growth\"\n",
    "    The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
    "\n",
    "    As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
    "    the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
    "\n",
    "    Here is the output schema:\n",
    "    ```\n",
    "    {\"properties\": {\"Topic\": {\"description\": \"Selected Topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ecc2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state={\"messages\": [\"Tell me about India's Industrial Growth\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75354640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about India's Industrial Growth\n",
      "Topic='India' Reasoning=\"The user query mentions India's Industrial Growth, which is directly related to the country.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['India']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_1(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db253cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state):\n",
    "    print('-> Router ->')\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    print(last_message)\n",
    "    if 'India' in last_message:\n",
    "        return 'RAG Call'\n",
    "    else:\n",
    "        return 'LLM Call'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01287dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(state):\n",
    "    print('-> Calling RAG ->')\n",
    "    messages = state['messages']\n",
    "    question = messages[0] ## Fetching the user question\n",
    "    print(question)\n",
    "\n",
    "    template = \"\"\"Answer the question based only on the following context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "    print(prompt)\n",
    "\n",
    "    retrieval_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm_groq\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "    result = retrieval_chain.invoke(question)\n",
    "    return  {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70c6a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_3(state):\n",
    "    print('-> Calling LLM ->')\n",
    "\n",
    "    messages = state['messages']\n",
    "    question = messages[0] ## Fetching the user question\n",
    "\n",
    "    # Normal LLM call\n",
    "    complete_query = \"Anwer the follow question with your knowledge of the real world. Following is the user question: \" + question\n",
    "    response = llm_groq.invoke(complete_query)\n",
    "    return {\"messages\": [response.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7e6c00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.AgentState"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07fec640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,END\n",
    "\n",
    "workflow5 = StateGraph(AgentState) ### StateGraph with AgentState\n",
    "\n",
    "\n",
    "workflow5.add_node(\"agent\", function_1)\n",
    "\n",
    "workflow5.add_node(\"RAG\", function_2)\n",
    "\n",
    "workflow5.add_node(\"LLM\", function_3)\n",
    "\n",
    "\n",
    "workflow5.set_entry_point(\"agent\")\n",
    "\n",
    "workflow5.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    \n",
    "    \n",
    "    router,\n",
    "    {\n",
    "        \"RAG Call\": \"RAG\",\n",
    "        \"LLM Call\": \"LLM\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow5.add_edge(\"RAG\",END)\n",
    "\n",
    "\n",
    "workflow5.add_edge(\"LLM\",END)\n",
    "\n",
    "\n",
    "app5=workflow5.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6468b810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app5.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aed93c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [\"Tell me about India's Industrial Growth\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66229e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about India's Industrial Growth\n",
      "Topic='India' Reasoning=\"The user query mentions India's Industrial Growth, which is directly related to the country.\"\n",
      "-> Router ->\n",
      "India\n",
      "-> Calling RAG ->\n",
      "Tell me about India's Industrial Growth\n",
      "input_variables=['context', 'question'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n    {context}\\n\\n    Question: {question}\\n    '), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "output = app5.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572a6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraphvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
